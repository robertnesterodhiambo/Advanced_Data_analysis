{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e6260cf0",
      "metadata": {
        "id": "e6260cf0"
      },
      "source": [
        "# **BDTs at work: the $\\Omega$ analysis**\n",
        "\n",
        "The goal of this tutorial is to provide an example of binary classification with machine learning techniques applied to an ALICE analysis. This tutorial is based on the measurement of the invariant mass of the $\\mathrm{\\Omega}$ , through its cascade decay channel $\\mathrm{\\Omega^-} \\rightarrow \\mathrm{\\Lambda} + K^- \\rightarrow p + \\pi^- + K^-$. We will need two samples:\n",
        "- Real data: Pb--Pb collisions at $s_{\\sqrt{NN}} = 5.02$ TeV (LHC18qr, subsample)\n",
        "- Anchored MC production: LHC21l5\n",
        "\n",
        "At the end of the tutorial we will be able to see the peak of the $\\mathrm{\\Omega}$ !\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f35bcb5",
      "metadata": {
        "id": "8f35bcb5"
      },
      "source": [
        "<img src=\"img/omega_dec.png\"\n",
        "     align=\"center\"\n",
        "     width=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bb651de",
      "metadata": {
        "id": "0bb651de"
      },
      "source": [
        "#### First, we need some libraries ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61974b28",
      "metadata": {
        "id": "61974b28"
      },
      "outputs": [],
      "source": [
        "### standard sci-py libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import uproot ### to read, convert, inspect ROOT TTrees\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd7657f9",
      "metadata": {
        "id": "dd7657f9"
      },
      "source": [
        "One tip before starting: to access the documentation associated to each function we are going to call just type Shift+Tab after the first parenthesis of the function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ec88a72",
      "metadata": {
        "id": "5ec88a72"
      },
      "source": [
        "## Reading trees with uproot, handling them with pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4090cdb0",
      "metadata": {
        "id": "4090cdb0"
      },
      "source": [
        "Uproot (https://github.com/scikit-hep/uproot4) is a Python package that provides tools for reading/writing ROOT files using Python and Numpy (does not depend on ROOT) and is primarly intended to stream data into machine learning libraries in Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf8f4fa1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf8f4fa1",
        "outputId": "aca8ac8a-b8e7-4e43-ad15-c839707ecfdb"
      },
      "outputs": [],
      "source": [
        "## first we have to download the trees\n",
        "\n",
        "#!curl -L https://cernbox.cern.ch/s/V05rgkoJfGe8x7K/download --output AnalysisResults-mc_reduced.root\n",
        "#!curl -L https://cernbox.cern.ch/s/ReP4m9tDJ6UfivD/download --output AnalysisResults_reduced.root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ae36449",
      "metadata": {
        "id": "8ae36449"
      },
      "outputs": [],
      "source": [
        "import uproot\n",
        "import pandas as pd  # Import the pandas library\n",
        "\n",
        "# Rest of your code remains unchanged\n",
        "#mc_file = uproot.open(\"/home/oem/repos/data/AnalysisResults_reduced.root\")\n",
        "#mc_file = uproot.open(\"/home/dragon/Downloads/whatsapp/AnalysisResults_reduced.root\")\n",
        "mc_file = uproot.open(\"~/github/data/AnalysisResults_reduced.root\")\n",
        "\n",
        "# Load the data from the \"XiOmegaTree\" TTree using NumPy arrays\n",
        "numpy_mc = mc_file[\"XiOmegaTree\"].arrays(library=\"np\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf74cdec",
      "metadata": {
        "id": "cf74cdec"
      },
      "outputs": [],
      "source": [
        "# Convert the NumPy arrays to a pandas DataFrame\n",
        "AnalysisResults_reduced = pd.DataFrame(numpy_mc)\n",
        "# Write the DataFrame to a CSV file\n",
        "#df.to_csv(\"AnalysisResults-mc_reduced.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe538c38",
      "metadata": {
        "id": "fe538c38"
      },
      "source": [
        "# file  2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cf8de4a",
      "metadata": {
        "id": "6cf8de4a"
      },
      "outputs": [],
      "source": [
        "#mc_file2 = uproot.open(\"/home/oem/repos/data/AnalysisResults-mc_reduced.root\")\n",
        "#mc_file2 = uproot.open(\"/home/dragon/Downloads/whatsapp/AnalysisResults-mc_reduced.root\")\n",
        "mc_file2 = uproot.open(\"~/github/data/AnalysisResults-mc_reduced.root\")\n",
        "\n",
        "mc_file2.keys()\n",
        "\n",
        "# Load the data from the \"XiOmegaTree\" TTree using NumPy arrays\n",
        "numpy_mc2 = mc_file2[\"XiOmegaTree\"].arrays(library=\"np\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5a23d49",
      "metadata": {
        "id": "c5a23d49"
      },
      "outputs": [],
      "source": [
        "# Convert the NumPy arrays to a pandas DataFrame\n",
        "AnalysisResultsmc_reduced = pd.DataFrame(numpy_mc2)\n",
        "# Write the DataFrame to a CSV file\n",
        "#AnalysisResults_mc_reduced.to_csv(\"AnalysisResults-mc_reduced.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c42d225",
      "metadata": {
        "id": "6c42d225"
      },
      "outputs": [],
      "source": [
        "#AnalysisResultsmc_reduced =  AnalysisResultsmc_reduced.iloc[:1000, :] # comment this line to run code with wholee data\n",
        "#AnalysisResults_reduced =  AnalysisResults_reduced.iloc[:1000, :] # cpomment this line to run whole code with whole data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d81e20f4",
      "metadata": {
        "id": "d81e20f4"
      },
      "source": [
        "# ABOUT THE DATA\n",
        "\n",
        "\n",
        "\n",
        "**1. pt (Transverse Momentum):** The transverse momentum, represented by the column \"pt,\" encapsulates the momentum component perpendicular to the direction of motion of particles within a particle collision. In the context of our analysis, it's akin to the sideways force exerted on an object as it moves forward. Just as a car may experience a lateral push while traveling along a straight path, particles exhibit transverse momentum as they navigate through space within the collision environment. This momentum component is essential for understanding the trajectories and interactions of particles, contributing valuable insights into their behavior and properties during the collision process.\n",
        "\n",
        "**2. eta (Pseudorapidity):** Pseudorapidity, denoted by the column \"eta,\" serves as a measure of the angle of a particle's trajectory relative to the beam axis within a particle collider. It provides crucial information about the distribution of particles across different regions of the detector. Think of pseudorapidity as analogous to the inclination angle of an object on a slope. Just as the steepness of a hill affects the trajectory of a rolling ball, pseudorapidity influences the distribution of particles within the detector, impacting their observable characteristics and interactions during collision events.\n",
        "\n",
        "**3. mass (Mass):** The mass column represents the amount of matter contained within particles participating in collision events. Similar to the weight of an object, mass indicates the intrinsic property defining the particle's resistance to changes in motion. In our analysis, mass serves as a fundamental parameter for characterizing particle properties and interactions. Much like how the weight of an object determines its behavior under gravitational forces, particle mass influences their trajectories, decay patterns, and interactions within the collision environment, offering valuable insights into their underlying properties and behavior.\n",
        "\n",
        "**4. ct (Decay Length):** Decay length, as indicated by the \"ct\" column, measures the distance traveled by particles before undergoing decay processes. It's akin to the distance covered by a thrown object before hitting the ground. Within the context of particle physics, decay length provides essential information about the stability and lifetime of particles, influencing their observable signatures and detection probabilities within the experimental setup. Understanding decay lengths enables researchers to infer crucial details about particle lifetimes, decay modes, and underlying interaction mechanisms, contributing to our comprehension of fundamental particle properties and behavior.\n",
        "\n",
        "**5. radius (Radius):** The radius column denotes the distance from the center to the edge of a particle's trajectory within the detector. Similar to the radius of a circle, it characterizes the size and spatial extent of particle trajectories observed during collision events. Understanding particle radii provides insights into their spatial distribution and interaction patterns within the detector environment. Much like how the radius of a circular object defines its size and boundary, particle radii delineate the spatial boundaries of particle trajectories, aiding in the identification and classification of particles based on their observable signatures.\n",
        "\n",
        "**6. radiusV0 (Radius V0):** RadiusV0 signifies the radius of a specific region of interest within the particle collision environment. Analogous to the radius of a target area within a larger space, it delineates a distinct region within the detector where specific particle interactions or decay processes are of interest. By focusing on the radiusV0 region, researchers can zoom in on specific particle interactions or phenomena, enabling targeted analysis and investigation of underlying processes. This localized perspective offers valuable insights into the dynamics and characteristics of particles within the designated region, enhancing our understanding of particle interactions and properties within the broader collision environment.\n",
        "\n",
        "**7. dcaBachPV (Distance of Closest Approach to Bachelor Particle Primary Vertex):** The dcaBachPV column represents the closest distance between a particle track and the primary vertex associated with the bachelor particle. It's analogous to the minimum separation between two entities within the particle collision environment. This parameter provides essential information about the spatial relationships between particles and primary vertices, offering insights into particle trajectories and interaction patterns. Similar to how the distance between two points defines their spatial proximity, dcaBachPV quantifies the proximity between particle tracks and primary vertices, aiding in the characterization and classification of particle interactions within the detector.\n",
        "\n",
        "**8. dcaV0PV (Distance of Closest Approach to V0 Particle Primary Vertex):** DcaV0PV measures the closest distance between a particle track and the primary vertex associated with the V0 particle. It's akin to the shortest distance between a particle's trajectory and a reference point within the collision environment. This parameter provides crucial information about the spatial relationship between particles and primary vertices, enabling researchers to infer valuable insights into particle trajectories and interaction dynamics. Much like how the distance between two points defines their spatial relationship, dcaV0PV quantifies the proximity between particle tracks and V0 particle primary vertices, facilitating the analysis and interpretation of particle interactions within the experimental setup.\n",
        "\n",
        "**9. dcaV0piPV (Distance of Closest Approach to V0 Pion Primary Vertex):** The dcaV0piPV column denotes the closest distance between a particle track and the primary vertex associated with the V0 pion. It's similar to the minimum separation between two points within the particle collision environment. This parameter provides essential information about the spatial relationships between particles and primary vertices, offering insights into particle trajectories and interaction patterns. Much like how the distance between two points defines their spatial proximity, dcaV0piPV quantifies the proximity between particle tracks and primary vertices, aiding in the characterization and classification of particle interactions within the detector.\n",
        "\n",
        "**10. dcaV0prPV (Distance of Closest Approach to V0 Proton Primary Vertex):** DcaV0prPV measures the closest distance between a particle track and the primary vertex associated with the V0 proton. It's similar to the shortest distance between a particle's trajectory and a reference point within the collision environment. This parameter provides crucial information about the spatial relationship between particles and primary vertices, enabling researchers to infer valuable insights into particle trajectories and interaction dynamics. Much like how the distance between two points defines their spatial relationship, dcaV0prPV quantifies the proximity between particle tracks and V0 particle primary vertices, facilitating the analysis and interpretation of particle interactions within the experimental setup."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "035bd6e9",
      "metadata": {
        "id": "035bd6e9"
      },
      "source": [
        "# Data Cleaning and Preprocessing:  \n",
        "\n",
        "## SIMULATED DATA\n",
        "\n",
        "### 1. MISSING VALUES\n",
        "\n",
        "The message \"No missing values found in the DataFrame\" indicates that after examining each column in the DataFrame `AnalysisResultsmc_reduced`, no missing values were detected. This suggests that all data entries in the DataFrame have been properly populated, with no null or NaN values present. It implies that the dataset is complete and ready for analysis without the need for additional data imputation or cleaning steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5d474b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5d474b2",
        "outputId": "06473dd9-98d9-471d-961e-339363f8e794"
      },
      "outputs": [],
      "source": [
        "# Check for missing values in each column\n",
        "missing_values = AnalysisResultsmc_reduced.isna().sum()\n",
        "\n",
        "# Display the columns with missing values, if any\n",
        "columns_with_missing_values = missing_values[missing_values > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p3qRXY_wZT2-",
      "metadata": {
        "id": "p3qRXY_wZT2-"
      },
      "outputs": [],
      "source": [
        "# Downcast numeric types\n",
        "for col in AnalysisResultsmc_reduced.select_dtypes(include=['int', 'float']).columns:\n",
        "    AnalysisResultsmc_reduced[col] = pd.to_numeric(AnalysisResultsmc_reduced[col], downcast='float')\n",
        "\n",
        "# Convert categorical columns to category data type\n",
        "for col in AnalysisResultsmc_reduced.select_dtypes(include=['object']).columns:\n",
        "    AnalysisResultsmc_reduced[col] = AnalysisResultsmc_reduced[col].astype('category')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6545e05e",
      "metadata": {
        "id": "6545e05e"
      },
      "source": [
        "### 2. outliers, and inconsistencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4a2b463",
      "metadata": {
        "id": "c4a2b463"
      },
      "outputs": [],
      "source": [
        "# Filter columns with integer values\n",
        "integer_columns = AnalysisResultsmc_reduced.select_dtypes(exclude='object').columns\n",
        "\n",
        "# Create a new DataFrame with only integer columns\n",
        "AnalysisResultsmc_reduced_integer = AnalysisResultsmc_reduced[integer_columns]\n",
        "\n",
        "# Descriptive statistics\n",
        "#integer_describe = AnalysisResultsmc_reduced_integer.describe()\n",
        "#print(integer_describe)\n",
        "\n",
        "# Box plot for each integer column\n",
        "#import matplotlib.pyplot as plt\n",
        "#plt.figure(figsize=(10, 6))\n",
        "#AnalysisResultsmc_reduced_integer.boxplot()\n",
        "#plt.title('Box plot of Integer Columns')\n",
        "#plt.ylabel('Value')\n",
        "#plt.xlabel('Columns')\n",
        "#plt.xticks(rotation=45)\n",
        "#plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76cc29d1",
      "metadata": {
        "id": "76cc29d1"
      },
      "outputs": [],
      "source": [
        "# Filter columns with integer values\n",
        "integer_columns = AnalysisResultsmc_reduced.select_dtypes(exclude='object').columns\n",
        "\n",
        "# Create a new DataFrame with only integer columns\n",
        "AnalysisResultsmc_reduced_integer = AnalysisResultsmc_reduced[integer_columns]\n",
        "\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Calculate z-score for each value in integer columns\n",
        "z_scores = AnalysisResultsmc_reduced_integer.apply(zscore)\n",
        "\n",
        "# Define threshold for outlier detection\n",
        "threshold = 3\n",
        "\n",
        "# Find outliers\n",
        "outliers = (z_scores > threshold) | (z_scores < -threshold)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_D9JOEqUXsjv",
      "metadata": {
        "id": "_D9JOEqUXsjv"
      },
      "outputs": [],
      "source": [
        "# Downcast numeric types\n",
        "for col in AnalysisResultsmc_reduced.select_dtypes(include=['int', 'float']).columns:\n",
        "    AnalysisResultsmc_reduced[col] = pd.to_numeric(AnalysisResultsmc_reduced[col], downcast='float')\n",
        "\n",
        "# Convert categorical columns to category data type\n",
        "for col in AnalysisResultsmc_reduced.select_dtypes(include=['object']).columns:\n",
        "    AnalysisResultsmc_reduced[col] = AnalysisResultsmc_reduced[col].astype('category')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b8b9c1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the variables you want to keep\n",
        "keep_variables = ['AnalysisResultsmc_reduced', 'AnalysisResultsmc_reduced_integer']\n",
        "\n",
        "# Get a dictionary of all variables in the current namespace\n",
        "all_variables = globals().copy()\n",
        "\n",
        "# Remove all variables except the ones in keep_variables\n",
        "for var_name in list(all_variables.keys()):\n",
        "    if var_name not in keep_variables:\n",
        "        del globals()[var_name]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45cb8157",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "baa7056a",
      "metadata": {
        "id": "baa7056a"
      },
      "source": [
        "### 3. STANDERDIZATION AND NORMALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de688746",
      "metadata": {
        "id": "de688746"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Standardize the data\n",
        "standardized_data = scaler.fit_transform(AnalysisResultsmc_reduced)\n",
        "# Assuming standardized_data is the standardized array and AnalysisResultsmc_reduced is the DataFrame\n",
        "standardized_df = pd.DataFrame(standardized_data, columns=AnalysisResultsmc_reduced.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7f2839c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "e7f2839c",
        "outputId": "82438d18-3d16-4c1a-ee74-6c0dee144592"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Normalize the standardized data\n",
        "normalized_data = scaler.fit_transform(standardized_df)\n",
        "\n",
        "# Convert the normalized data back to a DataFrame\n",
        "normalized_df = pd.DataFrame(normalized_data, columns=AnalysisResultsmc_reduced.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc3da48c",
      "metadata": {
        "id": "fc3da48c"
      },
      "source": [
        "## 2. REAL DATA\n",
        "\n",
        "### 1.MISSING VALUES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67ea2a3f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67ea2a3f",
        "outputId": "978b643c-2b88-4059-8452-08bec1345918"
      },
      "outputs": [],
      "source": [
        "# Check for missing values in each column AnalysisResults_reduced\n",
        "missing_values = AnalysisResults_reduced.isna().sum()\n",
        "\n",
        "# Display the columns with missing values, if any\n",
        "columns_with_missing_values = missing_values[missing_values > 0]\n",
        "if not columns_with_missing_values.empty:\n",
        "    print(\"Columns with missing values:\")\n",
        "    print(columns_with_missing_values)\n",
        "else:\n",
        "    print(\"No missing values found in the DataFrame.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deb53729",
      "metadata": {
        "id": "deb53729"
      },
      "source": [
        "### 2. OUTLIERS AND INCONCISTSNECIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3956fbbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3956fbbb",
        "outputId": "fc09247b-15f9-4981-8dbd-4bd56a0b140c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Filter columns with integer values\n",
        "integer_columns = AnalysisResults_reduced.select_dtypes(exclude='object').columns\n",
        "\n",
        "# Create a new DataFrame with only integer columns\n",
        "AnalysisResults_reduced_integer = AnalysisResults_reduced[integer_columns]\n",
        "\n",
        "# Descriptive statistics\n",
        "#integer_describe = AnalysisResults_reduced_integer.describe()\n",
        "#print(integer_describe)\n",
        "\n",
        "# Box plot for each integer column\n",
        "#import matplotlib.pyplot as plt\n",
        "#plt.figure(figsize=(10, 6))\n",
        "#AnalysisResults_reduced_integer.boxplot()\n",
        "#plt.title('Box plot of Integer Columns')\n",
        "#plt.ylabel('Value')\n",
        "#plt.xlabel('Columns')\n",
        "#plt.xticks(rotation=45)\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Filter columns with integer values\n",
        "integer_columns = AnalysisResults_reduced.select_dtypes(exclude='object').columns\n",
        "\n",
        "# Create a new DataFrame with only integer columns\n",
        "AnalysisResults_reduced_integer = AnalysisResults_reduced[integer_columns]\n",
        "\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Calculate z-score for each value in integer columns\n",
        "z_scores = AnalysisResults_reduced_integer.apply(zscore)\n",
        "\n",
        "# Define threshold for outlier detection\n",
        "threshold = 3\n",
        "\n",
        "# Find outliers\n",
        "outliers = (z_scores > threshold) | (z_scores < -threshold)\n",
        "\n",
        "# Display outliers\n",
        "print(\"Outliers:\")\n",
        "print(outliers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da145384",
      "metadata": {
        "id": "da145384"
      },
      "source": [
        "### 3. STANDARDIZATION AND NORMALIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "849a1f19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "849a1f19",
        "outputId": "82eb88e9-73d8-44cd-ac4f-99327be54a29"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Standardize the data\n",
        "standardized_data = scaler.fit_transform(AnalysisResults_reduced)\n",
        "# Assuming standardized_data is the standardized array and AnalysisResults_reduced is the DataFrame\n",
        "standardized_df_real = pd.DataFrame(standardized_data, columns=AnalysisResults_reduced.columns)\n",
        "\n",
        "standardized_df_real\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d8eb071",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "0d8eb071",
        "outputId": "11a74049-b61e-4a47-849f-a2581e3e72a4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Normalize the standardized data\n",
        "normalized_data = scaler.fit_transform(standardized_df_real)\n",
        "\n",
        "# Convert the normalized data back to a DataFrame\n",
        "normalized_df_real = pd.DataFrame(normalized_data, columns=AnalysisResults_reduced.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "624535d1",
      "metadata": {
        "id": "624535d1"
      },
      "source": [
        "# EDA\n",
        "## simulated data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef64fc26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ef64fc26",
        "outputId": "4ea94273-92a2-47ed-9ac7-1990f30772b2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Subset of columns for EDA (you can modify this list based on your specific requirements)\n",
        "columns_subset = ['pt', 'eta', 'mass', 'ct', 'radius', 'radiusV0', 'dcaBachPV', 'dcaV0PV', 'dcaV0piPV',\n",
        "                  'dcaV0prPV', 'tpcNsigmaBach', 'tpcNsigmaV0Pr', 'tpcNsigmaV0Pi', 'centrality']\n",
        "\n",
        "# Descriptive statistics\n",
        "print(normalized_df[columns_subset].describe())\n",
        "\n",
        "# Histograms\n",
        "normalized_df[columns_subset].hist(bins=20, figsize=(15, 10))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Boxplots\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.boxplot(data=normalized_df[columns_subset])\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Correlation heatmap\n",
        "correlation_matrix = normalized_df[columns_subset].corr()\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b8fe107",
      "metadata": {
        "id": "0b8fe107"
      },
      "source": [
        "## REAL DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ebf661f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8ebf661f",
        "outputId": "b5d66aaf-356b-4317-f086-204db0db4b99"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Subset of columns for EDA (you can modify this list based on your specific requirements)\n",
        "columns_subset = ['pt', 'eta', 'mass', 'ct', 'radius', 'radiusV0', 'dcaBachPV', 'dcaV0PV', 'dcaV0piPV',\n",
        "                  'dcaV0prPV', 'tpcNsigmaBach', 'tpcNsigmaV0Pr', 'tpcNsigmaV0Pi', 'centrality']\n",
        "\n",
        "# Descriptive statistics\n",
        "print(normalized_df_real[columns_subset].describe())\n",
        "\n",
        "# Histograms\n",
        "normalized_df_real[columns_subset].hist(bins=20, figsize=(15, 10))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Boxplots\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.boxplot(data=normalized_df_real[columns_subset])\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Correlation heatmap\n",
        "correlation_matrix = normalized_df_real[columns_subset].corr()\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfbc0a33",
      "metadata": {
        "id": "dfbc0a33"
      },
      "source": [
        "# Model Selection:\n",
        "##  Model Training and Evaluation:\n",
        "\n",
        "### 1. Simulated data\n",
        "\n",
        "#### 1.Random Forest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a15dba84",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a15dba84",
        "outputId": "23f2613c-446d-48d5-a9dc-6f7d33932b2c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = normalized_df.drop(columns=['index'])\n",
        "y = normalized_df['index']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest model\n",
        "random_forest_model = RandomForestRegressor()\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "random_forest_score = random_forest_model.score(X_test, y_test)\n",
        "print(\"Random Forest Score:\", random_forest_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "343e62bb",
      "metadata": {
        "id": "343e62bb"
      },
      "source": [
        "## model plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a0a9e23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "6a0a9e23",
        "outputId": "f1e70161-855e-4232-d7dc-5dd5f800f629"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize and train the Random Forest model\n",
        "random_forest_model = RandomForestRegressor(random_state=42)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on test data\n",
        "y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "# Plot actual vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Actual vs Predicted values')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9136868d",
      "metadata": {
        "id": "9136868d"
      },
      "source": [
        "### RF hyper parameter tuing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8dee3b3",
      "metadata": {
        "id": "d8dee3b3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20],       # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "random_forest_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=random_forest_model, param_grid=param_grid, cv=5, n_jobs=1)\n",
        "\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model\n",
        "best_model_score = best_model.score(X_test, y_test)\n",
        "print(\"Best Random Forest Score:\", best_model_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ac970c8",
      "metadata": {
        "id": "9ac970c8"
      },
      "source": [
        "#### 2. Support Vector Machine (SVM):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f43d678",
      "metadata": {
        "id": "7f43d678"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# Initialize and train the SVM model\n",
        "svm_model = SVR()\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "svm_score = svm_model.score(X_test, y_test)\n",
        "print(\"SVM Score:\", svm_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebd87127",
      "metadata": {
        "id": "ebd87127"
      },
      "source": [
        "##3 model plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96416f13",
      "metadata": {
        "id": "96416f13"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predictions on test data\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Plot actual vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_svm, color='blue')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Actual vs Predicted values (SVM)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a68bb243",
      "metadata": {
        "id": "a68bb243"
      },
      "source": [
        "#### hyper paramter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f184bebf",
      "metadata": {
        "id": "f184bebf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [1, 0.1, 0.01, 0.001],\n",
        "    'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
        "}\n",
        "\n",
        "# Initialize the grid search\n",
        "grid_search_svm = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5, n_jobs=1)\n",
        "\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search_svm.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(\"Best Hyperparameters:\", grid_search_svm.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c48b3504",
      "metadata": {
        "id": "c48b3504"
      },
      "source": [
        "#### 3.gradient boosting  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a88349d0",
      "metadata": {
        "id": "a88349d0"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Initialize and train the Gradient Boosting model\n",
        "gradient_boosting_model = GradientBoostingRegressor()\n",
        "gradient_boosting_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "gradient_boosting_score = gradient_boosting_model.score(X_test, y_test)\n",
        "print(\"Gradient Boosting Score:\", gradient_boosting_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "173acccd",
      "metadata": {
        "id": "173acccd"
      },
      "source": [
        "### model plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17998260",
      "metadata": {
        "id": "17998260"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predictions on test data\n",
        "y_pred_gradient_boosting = gradient_boosting_model.predict(X_test)\n",
        "\n",
        "# Plot actual vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_gradient_boosting, color='blue')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], linestyle='--', color='red')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted Values for Gradient Boosting Model')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9679649b",
      "metadata": {
        "id": "9679649b"
      },
      "source": [
        "#### hyper parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28ccdb10",
      "metadata": {
        "id": "28ccdb10"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search_gradient_boosting = GridSearchCV(estimator=gradient_boosting_model, param_grid=param_grid, cv=5, n_jobs=1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search_gradient_boosting.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(\"Best Hyperparameters:\", grid_search_gradient_boosting.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be506ea9",
      "metadata": {
        "id": "be506ea9"
      },
      "source": [
        "#### 4. Multilayer Perceptron (Neural Network):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7d72705",
      "metadata": {
        "id": "f7d72705"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Initialize and train the MLP model\n",
        "mlp_model = MLPRegressor()\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "mlp_score = mlp_model.score(X_test, y_test)\n",
        "print(\"Multilayer Perceptron Score:\", mlp_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b64c266b",
      "metadata": {
        "id": "b64c266b"
      },
      "source": [
        "### model plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "216e872b",
      "metadata": {
        "id": "216e872b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predictions\n",
        "y_pred = mlp_model.predict(X_test)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
        "plt.xlabel('True Values')\n",
        "plt.ylabel('Predictions')\n",
        "plt.title('MLP Model Predictions vs True Values')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0562b3ed",
      "metadata": {
        "id": "0562b3ed"
      },
      "source": [
        "### hyper paramter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25ab50a6",
      "metadata": {
        "id": "25ab50a6"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (150,)],\n",
        "    'activation': ['relu', 'tanh'],\n",
        "    'solver': ['adam', 'sgd'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "# Initialize the MLP regressor\n",
        "mlp_model = MLPRegressor(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=mlp_model, param_grid=param_grid, cv=5, verbose=2)\n",
        "\n",
        "# Perform grid search\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model\n",
        "best_model_score = best_model.score(X_test, y_test)\n",
        "print(\"Best Model Score:\", best_model_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c7aa3f4",
      "metadata": {
        "id": "4c7aa3f4"
      },
      "source": [
        "### Uncertainty Quantification Techniques:\n",
        "\n",
        "##### 1. Monte Carlo dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68f0648a",
      "metadata": {
        "id": "68f0648a"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "# Define and compile the model with Monte Carlo dropout\n",
        "def create_mc_dropout_model():\n",
        "    model = Sequential([\n",
        "        Dense(100, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        Dropout(0.5),\n",
        "        Dense(100, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Train the model with Monte Carlo dropout\n",
        "mc_dropout_model = create_mc_dropout_model()\n",
        "mc_dropout_model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
        "                     validation_data=(X_test, y_test),\n",
        "                     callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n",
        "\n",
        "# Generate predictions with Monte Carlo dropout\n",
        "n_samples = 100\n",
        "mc_dropout_predictions = np.stack([mc_dropout_model.predict(X_test) for _ in range(n_samples)])\n",
        "\n",
        "# Calculate uncertainty using standard deviation of predictions\n",
        "mc_dropout_uncertainty = np.std(mc_dropout_predictions, axis=0)\n",
        "\n",
        "# Calculate mean prediction\n",
        "mean_prediction = np.mean(mc_dropout_predictions, axis=0)\n",
        "\n",
        "# Evaluate the model\n",
        "mc_dropout_score = mc_dropout_model.evaluate(X_test, y_test)\n",
        "print(\"Multilayer Perceptron (Monte Carlo Dropout) Score:\", mc_dropout_score)\n",
        "\n",
        "# Print uncertainty metrics\n",
        "print(\"MC Dropout Uncertainty:\\n\", mc_dropout_uncertainty)\n",
        "print(\"\\nMean Prediction:\\n\", mean_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9d8ae03",
      "metadata": {
        "id": "d9d8ae03"
      },
      "source": [
        "### models plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2af258a7",
      "metadata": {
        "id": "2af258a7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.errorbar(range(len(y_test)), mean_prediction.flatten(), yerr=mc_dropout_uncertainty.flatten(), fmt='o', label='Predictions with Uncertainty')\n",
        "plt.plot(y_test, label='True Values', color='red')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Monte Carlo Dropout Predictions with Uncertainty')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd08283f",
      "metadata": {
        "id": "dd08283f"
      },
      "source": [
        "##### 2. bayesiam omference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5175a2cb",
      "metadata": {
        "id": "5175a2cb"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "# Initialize and train the Bayesian Ridge Regression model\n",
        "bayesian_model = BayesianRidge()\n",
        "bayesian_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "bayesian_score = bayesian_model.score(X_test, y_test)\n",
        "print(\"Bayesian Ridge Regression Score:\", bayesian_score)\n",
        "\n",
        "# Predictions\n",
        "bayesian_predictions = bayesian_model.predict(X_test)\n",
        "\n",
        "# Calculate uncertainty using standard deviation\n",
        "bayesian_uncertainty = np.std(bayesian_predictions)\n",
        "\n",
        "# Calculate mean prediction\n",
        "bayesian_mean_prediction = np.mean(bayesian_predictions)\n",
        "\n",
        "# Print uncertainty metrics\n",
        "print(\"Bayesian Uncertainty:\", bayesian_uncertainty)\n",
        "print(\"Bayesian Mean Prediction:\", bayesian_mean_prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad919721",
      "metadata": {
        "id": "ad919721"
      },
      "source": [
        "### model plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92a871e9",
      "metadata": {
        "id": "92a871e9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.errorbar(range(len(y_test)), bayesian_predictions, yerr=bayesian_uncertainty, fmt='o', label='Predictions with Uncertainty')\n",
        "plt.plot(y_test, label='True Values', color='red')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Bayesian Ridge Regression Predictions with Uncertainty')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93bd98da",
      "metadata": {
        "id": "93bd98da"
      },
      "source": [
        "##### 3. ensemble       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42db315e",
      "metadata": {
        "id": "42db315e"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialize and train the Random Forest Regressor model\n",
        "random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "random_forest_score = random_forest_model.score(X_test, y_test)\n",
        "print(\"Random Forest Regressor Score:\", random_forest_score)\n",
        "\n",
        "# Predictions\n",
        "random_forest_predictions = random_forest_model.predict(X_test)\n",
        "\n",
        "# Calculate uncertainty using standard deviation\n",
        "random_forest_uncertainty = np.std(random_forest_predictions)\n",
        "\n",
        "# Calculate mean prediction\n",
        "random_forest_mean_prediction = np.mean(random_forest_predictions)\n",
        "\n",
        "# Print uncertainty metrics\n",
        "print(\"Random Forest Uncertainty:\", random_forest_uncertainty)\n",
        "print(\"Random Forest Mean Prediction:\", random_forest_mean_prediction)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6ae37ff",
      "metadata": {
        "id": "e6ae37ff"
      },
      "source": [
        "### model plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8e1bfe1",
      "metadata": {
        "id": "c8e1bfe1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.errorbar(range(len(y_test)), random_forest_predictions, yerr=random_forest_uncertainty, fmt='o', label='Predictions with Uncertainty')\n",
        "plt.plot(y_test, label='True Values', color='red')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Random Forest Regressor Predictions with Uncertainty')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acb1e647",
      "metadata": {
        "id": "acb1e647"
      },
      "source": [
        "### 4. deep snemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24441d57",
      "metadata": {
        "id": "24441d57"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Define the function to create the neural network model\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(1)  # Output layer\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Initialize an empty list to store the ensemble models and predictions\n",
        "ensemble_models = []\n",
        "ensemble_predictions = []\n",
        "\n",
        "# Define the number of ensemble models\n",
        "num_models = 5\n",
        "\n",
        "# Create and train multiple models\n",
        "for _ in range(num_models):\n",
        "    # Create a new instance of the model\n",
        "    model = create_model()\n",
        "\n",
        "    # Train the model on the training data\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "    # Add the trained model to the ensemble\n",
        "    ensemble_models.append(model)\n",
        "\n",
        "    # Make predictions using the trained model\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Append predictions to the list of ensemble predictions\n",
        "    ensemble_predictions.append(predictions)\n",
        "\n",
        "# Compute uncertainty as the standard deviation of predictions\n",
        "ensemble_predictions_array = np.array(ensemble_predictions)\n",
        "uncertainty = np.std(ensemble_predictions_array, axis=0)\n",
        "\n",
        "# Evaluate the uncertainty score\n",
        "ensemble_uncertainty_score = np.mean(uncertainty)\n",
        "print(\"Deep Ensemble Uncertainty Score:\", ensemble_uncertainty_score)\n",
        "\n",
        "# Average the predictions from all models\n",
        "final_predictions = np.mean(ensemble_predictions_array, axis=0)\n",
        "\n",
        "# Evaluate the ensemble performance\n",
        "ensemble_score = tf.keras.metrics.mean_squared_error(y_test, final_predictions).numpy()\n",
        "print(\"Deep Ensemble Score:\", ensemble_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9215a88a",
      "metadata": {
        "id": "9215a88a"
      },
      "source": [
        "### plot model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc05afae",
      "metadata": {
        "id": "cc05afae"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.errorbar(range(len(y_test)), final_predictions, yerr=uncertainty, fmt='o', label='Predictions with Uncertainty')\n",
        "plt.plot(y_test, label='True Values', color='red')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Deep Ensemble Predictions with Uncertainty')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaae5cc9",
      "metadata": {
        "id": "eaae5cc9"
      },
      "source": [
        "####  5. pistemic, and aleatoric uncertainty decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "359fd00a",
      "metadata": {
        "id": "359fd00a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Define the function to create the neural network model\n",
        "def create_model():\n",
        "    inputs = keras.layers.Input(shape=(X_train.shape[1],))\n",
        "    hidden1 = keras.layers.Dense(64, activation='relu')(inputs)\n",
        "    hidden2 = keras.layers.Dense(64, activation='relu')(hidden1)\n",
        "    # Output layer for mean prediction\n",
        "    mean_output = keras.layers.Dense(1)(hidden2)\n",
        "    # Output layer for variance prediction (using softplus activation)\n",
        "    variance_output = keras.layers.Dense(1, activation='softplus')(hidden2)\n",
        "    model = keras.Model(inputs=inputs, outputs=[mean_output, variance_output])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Initialize an empty list to store the ensemble models and predictions\n",
        "ensemble_models = []\n",
        "ensemble_predictions = []\n",
        "\n",
        "# Define the number of ensemble models\n",
        "num_models = 5\n",
        "\n",
        "# Create and train multiple models\n",
        "for _ in range(num_models):\n",
        "    # Create a new instance of the model\n",
        "    model = create_model()\n",
        "\n",
        "    # Train the model on the training data\n",
        "    model.fit(X_train, [y_train, y_train], epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "    # Add the trained model to the ensemble\n",
        "    ensemble_models.append(model)\n",
        "\n",
        "    # Make predictions using the trained model\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Append predictions to the list of ensemble predictions\n",
        "    ensemble_predictions.append(predictions)\n",
        "\n",
        "# Compute ensemble mean and variance predictions\n",
        "ensemble_predictions_array = np.array(ensemble_predictions)\n",
        "mean_predictions = np.mean(ensemble_predictions_array[:, 0, :], axis=0)\n",
        "variance_predictions = np.mean(ensemble_predictions_array[:, 1, :], axis=0)\n",
        "\n",
        "# Compute aleatoric and epistemic uncertainties\n",
        "aleatoric_uncertainty = np.mean(variance_predictions)\n",
        "epistemic_uncertainty = np.mean(np.var(ensemble_predictions_array[:, 0, :], axis=0))\n",
        "\n",
        "# Evaluate the uncertainties\n",
        "print(\"Aleatoric Uncertainty:\", aleatoric_uncertainty)\n",
        "print(\"Epistemic Uncertainty:\", epistemic_uncertainty)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82fe7c9f",
      "metadata": {
        "id": "82fe7c9f"
      },
      "outputs": [],
      "source": [
        "# Flatten predictions\n",
        "mean_predictions_flat = mean_predictions.flatten()\n",
        "variance_predictions_flat = variance_predictions.flatten()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot true values\n",
        "plt.scatter(range(len(y_test)), y_test, color='red', label='True Values')\n",
        "\n",
        "# Plot mean predictions\n",
        "plt.plot(mean_predictions_flat, label='Mean Predictions', color='blue')\n",
        "\n",
        "# Plot uncertainty (e.g., standard deviation)\n",
        "plt.fill_between(range(len(y_test)), mean_predictions_flat - np.sqrt(variance_predictions_flat),\n",
        "                 mean_predictions_flat + np.sqrt(variance_predictions_flat), color='gray', alpha=0.3, label='Uncertainty')\n",
        "\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Model Predictions with Uncertainty')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a83d025b",
      "metadata": {
        "id": "a83d025b"
      },
      "source": [
        "### 6. Variational Inference:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c9982d5",
      "metadata": {
        "id": "8c9982d5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the probabilistic model\n",
        "def probabilistic_model(data):\n",
        "    # Prior distribution for the parameter\n",
        "    prior = np.random.normal(loc=0., scale=1.)\n",
        "    # Likelihood of the data given the parameter\n",
        "    likelihood = np.random.normal(loc=data, scale=1.)\n",
        "    # Return the joint distribution\n",
        "    return prior, likelihood\n",
        "\n",
        "# Perform Monte Carlo approximation for variational inference\n",
        "def monte_carlo_inference(data, num_samples=1000):\n",
        "    posterior_samples = []\n",
        "    for _ in range(num_samples):\n",
        "        prior_sample, likelihood_sample = probabilistic_model(data)\n",
        "        posterior_samples.append(prior_sample * likelihood_sample)\n",
        "    return np.array(posterior_samples)\n",
        "\n",
        "# Extract data from normalized_df (assuming it contains your features)\n",
        "data = normalized_df.values\n",
        "\n",
        "# Perform Monte Carlo inference\n",
        "posterior_samples = monte_carlo_inference(data)\n",
        "\n",
        "# Compute the posterior mean and standard deviation\n",
        "posterior_mean = np.mean(posterior_samples)\n",
        "posterior_stddev = np.std(posterior_samples)\n",
        "\n",
        "# Compute uncertainty as the standard deviation of the posterior samples\n",
        "uncertainty = np.std(posterior_samples)\n",
        "\n",
        "print(\"Posterior mean:\", posterior_mean)\n",
        "print(\"Posterior standard deviation:\", posterior_stddev)\n",
        "print(\"Uncertainty:\", uncertainty)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1b0d180",
      "metadata": {
        "id": "d1b0d180"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Flatten the posterior_samples array\n",
        "flattened_samples = posterior_samples.flatten()\n",
        "\n",
        "# Plot the histogram of flattened posterior samples\n",
        "plt.hist(flattened_samples, bins=30, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "plt.axvline(x=posterior_mean, color='red', linestyle='--', label='Posterior Mean')\n",
        "plt.xlabel('Parameter Value')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Posterior Distribution')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print uncertainty\n",
        "print(\"Uncertainty (Standard Deviation of Posterior):\", uncertainty)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b47473",
      "metadata": {
        "id": "78b47473"
      },
      "source": [
        "### 7. Confromal inferecne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e501ab3b",
      "metadata": {
        "id": "e501ab3b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'target_variable' is the name of the column you want to predict\n",
        "target_variable = 'pt'\n",
        "\n",
        "# Define the quantiles for quantile regression\n",
        "quantiles = [0.1, 0.5, 0.9]\n",
        "\n",
        "data = normalized_df\n",
        "# Initialize a list to store the quantile predictions\n",
        "quantile_results = []\n",
        "\n",
        "# Perform quantile regression for each quantile\n",
        "for quantile in quantiles:\n",
        "    # Fit quantile regression model\n",
        "    quantile_model = sm.QuantReg(data[target_variable], data.drop(columns=[target_variable])).fit(q=quantile)\n",
        "\n",
        "    # Predict conditional quantiles\n",
        "    quantile_prediction = quantile_model.predict(data.drop(columns=[target_variable]))\n",
        "\n",
        "    # Append quantile predictions to the results list\n",
        "    quantile_results.append(quantile_prediction)\n",
        "\n",
        "# Convert quantile results to a DataFrame\n",
        "quantile_df = pd.DataFrame(np.array(quantile_results).T, columns=[f'Quantile_{q}' for q in quantiles])\n",
        "\n",
        "# Calculate uncertainty as the difference between upper and lower quantiles\n",
        "quantile_df['Uncertainty'] = quantile_df['Quantile_0.9'] - quantile_df['Quantile_0.1']\n",
        "\n",
        "# Compute the mean uncertainty\n",
        "mean_uncertainty = quantile_df['Uncertainty'].mean()\n",
        "\n",
        "print(\"Mean uncertainty:\", mean_uncertainty)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5d2eb4b",
      "metadata": {
        "id": "d5d2eb4b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot actual values\n",
        "plt.scatter(data.index, data[target_variable], color='black', label='Actual')\n",
        "\n",
        "# Plot quantile predictions\n",
        "for i, quantile in enumerate(quantiles):\n",
        "    plt.plot(data.index, quantile_df[f'Quantile_{quantile}'], label=f'Quantile {quantile}', linestyle='--')\n",
        "\n",
        "# Plot uncertainty bounds\n",
        "plt.fill_between(data.index, quantile_df['Quantile_0.1'], quantile_df['Quantile_0.9'], color='gray', alpha=0.3, label='Uncertainty')\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel(target_variable)\n",
        "plt.title('Quantile Regression with Uncertainty Bounds')\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32821f9a",
      "metadata": {
        "id": "32821f9a"
      },
      "source": [
        "###  8. Bootstrapped ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce911aeb",
      "metadata": {
        "id": "ce911aeb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "from sklearn.linear_model import LinearRegression  # Example model, replace with your desired model\n",
        "\n",
        "# Define the ensemble size\n",
        "ensemble_size = 5  # You can adjust this as needed\n",
        "\n",
        "# Initialize an empty list to store the ensemble models\n",
        "ensemble_models = []\n",
        "\n",
        "# Define the number of bootstrap samples\n",
        "num_bootstraps = 100  # You can adjust this as needed\n",
        "\n",
        "# Perform bootstrapped ensemble\n",
        "for _ in range(ensemble_size):\n",
        "    # Sample a bootstrap sample with replacement\n",
        "    bootstrap_sample = resample(data, replace=True, n_samples=len(data))\n",
        "\n",
        "    # Train a model on the bootstrap sample (replace `YourModel` with your desired model)\n",
        "    model = LinearRegression()  # Example model, replace with your desired model\n",
        "    model.fit(bootstrap_sample.drop(columns=[target_variable]), bootstrap_sample[target_variable])\n",
        "\n",
        "    # Add the trained model to the ensemble\n",
        "    ensemble_models.append(model)\n",
        "\n",
        "# Make predictions using each model\n",
        "ensemble_predictions = [model.predict(data.drop(columns=[target_variable])) for model in ensemble_models]\n",
        "\n",
        "# Aggregate predictions from all models (for example, you can take the mean or median)\n",
        "final_predictions = np.mean(ensemble_predictions, axis=0)  # Adjust aggregation method as needed\n",
        "\n",
        "# Compute uncertainty as the standard deviation of predictions from all models\n",
        "uncertainty = np.std(ensemble_predictions, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "print(uncertainty)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "537d9c0f",
      "metadata": {
        "id": "537d9c0f"
      },
      "source": [
        "## model plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2d8756c",
      "metadata": {
        "id": "b2d8756c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming `final_predictions` contains your final predictions and `uncertainty` contains the uncertainty\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.errorbar(range(len(final_predictions)), final_predictions, yerr=uncertainty, fmt='o', color='blue', ecolor='red', capsize=5)\n",
        "plt.xlabel('Data Point Index')\n",
        "plt.ylabel('Prediction')\n",
        "plt.title('Bootstrapped Ensemble Predictions with Uncertainty')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f83619d",
      "metadata": {
        "id": "2f83619d"
      },
      "source": [
        "### 9. quantile regerssion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fcc2236",
      "metadata": {
        "id": "4fcc2236"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Define the quantiles for quantile regression\n",
        "quantiles = [0.1, 0.5, 0.9]  # You can adjust these as needed\n",
        "\n",
        "# Initialize a list to store the quantile predictions\n",
        "quantile_results = []\n",
        "\n",
        "# Perform quantile regression for each quantile\n",
        "for quantile in quantiles:\n",
        "    # Fit quantile regression model\n",
        "    quantile_model = sm.QuantReg(data[target_variable], data.drop(columns=[target_variable])).fit(q=quantile)\n",
        "\n",
        "    # Predict conditional quantiles\n",
        "    quantile_prediction = quantile_model.predict(data.drop(columns=[target_variable]))\n",
        "\n",
        "    # Append quantile predictions to the results list\n",
        "    quantile_results.append(quantile_prediction)\n",
        "\n",
        "# Convert quantile results to a DataFrame\n",
        "quantile_df = pd.DataFrame(np.array(quantile_results).T, columns=[f'Quantile_{q}' for q in quantiles])\n",
        "\n",
        "# Calculate uncertainty as the difference between upper and lower quantiles\n",
        "quantile_df['Uncertainty'] = quantile_df['Quantile_0.9'] - quantile_df['Quantile_0.1']\n",
        "\n",
        "# Compute the mean uncertainty\n",
        "mean_uncertainty = quantile_df['Uncertainty'].mean()\n",
        "\n",
        "print(\"Mean uncertainty:\", mean_uncertainty)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29502f15",
      "metadata": {
        "id": "29502f15"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the quantile predictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(data[target_variable], quantile_df['Quantile_0.5'], color='b', label='Median Prediction')\n",
        "plt.plot(data[target_variable], quantile_df['Quantile_0.1'], color='r', linestyle='--', label='10th Quantile')\n",
        "plt.plot(data[target_variable], quantile_df['Quantile_0.9'], color='r', linestyle='--', label='90th Quantile')\n",
        "plt.fill_between(data[target_variable], quantile_df['Quantile_0.1'], quantile_df['Quantile_0.9'], color='r', alpha=0.2)\n",
        "\n",
        "# Add uncertainty visualization with absolute values\n",
        "uncertainty_abs = quantile_df['Uncertainty'].abs()\n",
        "plt.errorbar(data[target_variable], quantile_df['Quantile_0.5'], yerr=uncertainty_abs, fmt='o', color='b', alpha=0.5, label='Uncertainty')\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel('Target Variable')\n",
        "plt.ylabel('Predicted Value')\n",
        "plt.title('Quantile Regression with Uncertainty')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e7fc1ef",
      "metadata": {
        "id": "9e7fc1ef"
      },
      "source": [
        "### 10. kenrel density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57145525",
      "metadata": {
        "id": "57145525"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Assuming `data` contains your dataset and `target_variable` is the column you want to predict\n",
        "# Extract the target variable data\n",
        "target_data = data[target_variable].values.reshape(-1, 1)\n",
        "\n",
        "# Define the range of values over which to estimate the PDF\n",
        "x_values = np.linspace(target_data.min(), target_data.max(), 1000).reshape(-1, 1)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100  # Adjust as needed\n",
        "\n",
        "# Initialize an empty list to store density estimates from each bootstrap sample\n",
        "density_estimates = []\n",
        "\n",
        "# Fit kernel density estimation model and perform bootstrapping\n",
        "for _ in range(num_bootstraps):\n",
        "    # Sample a bootstrap sample with replacement\n",
        "    bootstrap_sample = resample(target_data, replace=True, n_samples=len(target_data))\n",
        "\n",
        "    # Fit kernel density estimation model on the bootstrap sample\n",
        "    kde = KernelDensity(bandwidth=0.1, kernel='gaussian')  # Adjust bandwidth and kernel as needed\n",
        "    kde.fit(bootstrap_sample)\n",
        "\n",
        "    # Estimate the PDF at the specified points\n",
        "    log_density_values = kde.score_samples(x_values)  # Log-density values\n",
        "\n",
        "    # Convert log-density values to actual density values\n",
        "    density_values = np.exp(log_density_values)\n",
        "\n",
        "    # Append density estimate to the list\n",
        "    density_estimates.append(density_values)\n",
        "\n",
        "# Compute the mean and standard deviation of density estimates across bootstrap samples\n",
        "mean_density = np.mean(density_estimates, axis=0)\n",
        "std_density = np.std(density_estimates, axis=0)\n",
        "\n",
        "# Compute upper and lower bounds of the confidence interval\n",
        "lower_bound = mean_density - 1.96 * std_density  # 95% confidence interval\n",
        "upper_bound = mean_density + 1.96 * std_density  # 95% confidence interval\n",
        "\n",
        "# Plot the estimated probability density function (PDF) with uncertainty\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x_values, mean_density, color='b', label='Mean PDF')\n",
        "plt.fill_between(x_values.ravel(), lower_bound, upper_bound, color='r', alpha=0.2, label='95% Confidence Interval')\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel('Target Variable')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.title('Kernel Density Estimation with Uncertainty')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "162a8a65",
      "metadata": {
        "id": "162a8a65"
      },
      "source": [
        "# Model Selection:\n",
        "##  Model Training and Evaluation:\n",
        "\n",
        "### 1. REAL DATA\n",
        "\n",
        "#### 1.Random Forest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80a61f5f",
      "metadata": {
        "id": "80a61f5f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = normalized_df_real.drop(columns=['index'])\n",
        "y = normalized_df_real['index']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Random Forest model\n",
        "random_forest_model = RandomForestRegressor()\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "random_forest_score = random_forest_model.score(X_test, y_test)\n",
        "print(\"Random Forest Score:\", random_forest_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cfa03c3",
      "metadata": {
        "id": "1cfa03c3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize and train the Random Forest model\n",
        "random_forest_model = RandomForestRegressor(random_state=42)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on test data\n",
        "y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "# Plot actual vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Actual vs Predicted values')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "808c1b7f",
      "metadata": {
        "id": "808c1b7f"
      },
      "source": [
        "### hyper paramter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff903a84",
      "metadata": {
        "id": "ff903a84"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20],       # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4]      # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "random_forest_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=random_forest_model, param_grid=param_grid, cv=5, n_jobs=1)\n",
        "\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model\n",
        "best_model_score = best_model.score(X_test, y_test)\n",
        "print(\"Best Random Forest Score:\", best_model_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e57af926",
      "metadata": {
        "id": "e57af926"
      },
      "source": [
        "#### 2. Support Vector Machine (SVM):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c966cd",
      "metadata": {
        "id": "f6c966cd"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# Initialize and train the SVM model\n",
        "svm_model = SVR()\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "svm_score = svm_model.score(X_test, y_test)\n",
        "print(\"SVM Score:\", svm_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d7c536",
      "metadata": {
        "id": "56d7c536"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predictions on test data\n",
        "y_pred_svm = svm_model.predict(X_test)\n",
        "\n",
        "# Plot actual vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_svm, color='blue')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.title('Actual vs Predicted values (SVM)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0036d663",
      "metadata": {
        "id": "0036d663"
      },
      "source": [
        "#### hyper paramter tungin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e77cca",
      "metadata": {
        "id": "15e77cca"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [1, 0.1, 0.01, 0.001],\n",
        "    'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
        "}\n",
        "\n",
        "# Initialize the grid search\n",
        "grid_search_svm = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=5, n_jobs=1)\n",
        "\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search_svm.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(\"Best Hyperparameters:\", grid_search_svm.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee13a827",
      "metadata": {
        "id": "ee13a827"
      },
      "source": [
        "#### 3.gradient boosting  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45f7303f",
      "metadata": {
        "id": "45f7303f"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Initialize and train the Gradient Boosting model\n",
        "gradient_boosting_model = GradientBoostingRegressor()\n",
        "gradient_boosting_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "gradient_boosting_score = gradient_boosting_model.score(X_test, y_test)\n",
        "print(\"Gradient Boosting Score:\", gradient_boosting_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcd842cb",
      "metadata": {
        "id": "dcd842cb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predictions on test data\n",
        "y_pred_gradient_boosting = gradient_boosting_model.predict(X_test)\n",
        "\n",
        "# Plot actual vs predicted values\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, y_pred_gradient_boosting, color='blue')\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], linestyle='--', color='red')\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted Values for Gradient Boosting Model')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "191cd2fe",
      "metadata": {
        "id": "191cd2fe"
      },
      "source": [
        "###3 tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "351a21d1",
      "metadata": {
        "id": "351a21d1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search_gradient_boosting = GridSearchCV(estimator=gradient_boosting_model, param_grid=param_grid, cv=5, n_jobs=1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search_gradient_boosting.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(\"Best Hyperparameters:\", grid_search_gradient_boosting.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c82140b",
      "metadata": {
        "id": "7c82140b"
      },
      "source": [
        "#### 4. Multilayer Perceptron (Neural Network):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d62aac0a",
      "metadata": {
        "id": "d62aac0a"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Initialize and train the MLP model\n",
        "mlp_model = MLPRegressor()\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "mlp_score = mlp_model.score(X_test, y_test)\n",
        "print(\"Multilayer Perceptron Score:\", mlp_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e91f5fe6",
      "metadata": {
        "id": "e91f5fe6"
      },
      "source": [
        "### Uncertainty Quantification Techniques:\n",
        "\n",
        "##### 1. Monte Carlo dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b86e7fc",
      "metadata": {
        "id": "0b86e7fc"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "# Define and compile the model with Monte Carlo dropout\n",
        "def create_mc_dropout_model():\n",
        "    model = Sequential([\n",
        "        Dense(100, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        Dropout(0.5),\n",
        "        Dense(100, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Train the model with Monte Carlo dropout\n",
        "mc_dropout_model = create_mc_dropout_model()\n",
        "mc_dropout_model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
        "                     validation_data=(X_test, y_test),\n",
        "                     callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n",
        "\n",
        "# Generate predictions with Monte Carlo dropout\n",
        "n_samples = 100\n",
        "mc_dropout_predictions = np.stack([mc_dropout_model.predict(X_test) for _ in range(n_samples)])\n",
        "\n",
        "# Calculate uncertainty using standard deviation of predictions\n",
        "mc_dropout_uncertainty = np.std(mc_dropout_predictions, axis=0)\n",
        "\n",
        "# Calculate mean prediction\n",
        "mean_prediction = np.mean(mc_dropout_predictions, axis=0)\n",
        "\n",
        "# Evaluate the model\n",
        "mc_dropout_score = mc_dropout_model.evaluate(X_test, y_test)\n",
        "print(\"Multilayer Perceptron (Monte Carlo Dropout) Score:\", mc_dropout_score)\n",
        "\n",
        "# Print uncertainty metrics\n",
        "print(\"MC Dropout Uncertainty:\\n\", mc_dropout_uncertainty)\n",
        "print(\"\\nMean Prediction:\\n\", mean_prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faff6cfb",
      "metadata": {
        "id": "faff6cfb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.errorbar(range(len(y_test)), mean_prediction.flatten(), yerr=mc_dropout_uncertainty.flatten(), fmt='o', label='Predictions with Uncertainty')\n",
        "plt.plot(y_test, label='True Values', color='red')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Monte Carlo Dropout Predictions with Uncertainty')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6e7d403",
      "metadata": {
        "id": "b6e7d403"
      },
      "source": [
        "##### 2. bayesiam omference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2be3da4",
      "metadata": {
        "id": "c2be3da4"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "\n",
        "# Initialize and train the Bayesian Ridge Regression model\n",
        "bayesian_model = BayesianRidge()\n",
        "bayesian_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "bayesian_score = bayesian_model.score(X_test, y_test)\n",
        "print(\"Bayesian Ridge Regression Score:\", bayesian_score)\n",
        "\n",
        "# Predictions\n",
        "bayesian_predictions = bayesian_model.predict(X_test)\n",
        "\n",
        "# Calculate uncertainty using standard deviation\n",
        "bayesian_uncertainty = np.std(bayesian_predictions)\n",
        "\n",
        "# Calculate mean prediction\n",
        "bayesian_mean_prediction = np.mean(bayesian_predictions)\n",
        "\n",
        "# Print uncertainty metrics\n",
        "print(\"Bayesian Uncertainty:\", bayesian_uncertainty)\n",
        "print(\"Bayesian Mean Prediction:\", bayesian_mean_prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b899dd1f",
      "metadata": {
        "id": "b899dd1f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.errorbar(range(len(y_test)), bayesian_predictions, yerr=bayesian_uncertainty, fmt='o', label='Predictions with Uncertainty')\n",
        "plt.plot(y_test, label='True Values', color='red')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Bayesian Ridge Regression Predictions with Uncertainty')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdbaa319",
      "metadata": {
        "id": "bdbaa319"
      },
      "source": [
        "##### 3. ensemble       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d65dd6c3",
      "metadata": {
        "id": "d65dd6c3"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Initialize and train the Random Forest Regressor model\n",
        "random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "random_forest_score = random_forest_model.score(X_test, y_test)\n",
        "print(\"Random Forest Regressor Score:\", random_forest_score)\n",
        "\n",
        "# Predictions\n",
        "random_forest_predictions = random_forest_model.predict(X_test)\n",
        "\n",
        "# Calculate uncertainty using standard deviation\n",
        "random_forest_uncertainty = np.std(random_forest_predictions)\n",
        "\n",
        "# Calculate mean prediction\n",
        "random_forest_mean_prediction = np.mean(random_forest_predictions)\n",
        "\n",
        "# Print uncertainty metrics\n",
        "print(\"Random Forest Uncertainty:\", random_forest_uncertainty)\n",
        "print(\"Random Forest Mean Prediction:\", random_forest_mean_prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4beb6a3",
      "metadata": {
        "id": "d4beb6a3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.errorbar(range(len(y_test)), random_forest_predictions, yerr=random_forest_uncertainty, fmt='o', label='Predictions with Uncertainty')\n",
        "plt.plot(y_test, label='True Values', color='red')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Random Forest Regressor Predictions with Uncertainty')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03bb81c5",
      "metadata": {
        "id": "03bb81c5"
      },
      "source": [
        "### 4. deep snemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c35b873",
      "metadata": {
        "id": "8c35b873"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Define the function to create the neural network model\n",
        "def create_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(1)  # Output layer\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Initialize an empty list to store the ensemble models and predictions\n",
        "ensemble_models = []\n",
        "ensemble_predictions = []\n",
        "\n",
        "# Define the number of ensemble models\n",
        "num_models = 5\n",
        "\n",
        "# Create and train multiple models\n",
        "for _ in range(num_models):\n",
        "    # Create a new instance of the model\n",
        "    model = create_model()\n",
        "\n",
        "    # Train the model on the training data\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "    # Add the trained model to the ensemble\n",
        "    ensemble_models.append(model)\n",
        "\n",
        "    # Make predictions using the trained model\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Append predictions to the list of ensemble predictions\n",
        "    ensemble_predictions.append(predictions)\n",
        "\n",
        "# Compute uncertainty as the standard deviation of predictions\n",
        "ensemble_predictions_array = np.array(ensemble_predictions)\n",
        "uncertainty = np.std(ensemble_predictions_array, axis=0)\n",
        "\n",
        "# Evaluate the uncertainty score\n",
        "ensemble_uncertainty_score = np.mean(uncertainty)\n",
        "print(\"Deep Ensemble Uncertainty Score:\", ensemble_uncertainty_score)\n",
        "\n",
        "# Average the predictions from all models\n",
        "final_predictions = np.mean(ensemble_predictions_array, axis=0)\n",
        "\n",
        "# Evaluate the ensemble performance\n",
        "ensemble_score = tf.keras.metrics.mean_squared_error(y_test, final_predictions).numpy()\n",
        "print(\"Deep Ensemble Score:\", ensemble_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80569b34",
      "metadata": {
        "id": "80569b34"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.errorbar(range(len(y_test)), final_predictions, yerr=uncertainty, fmt='o', label='Predictions with Uncertainty')\n",
        "plt.plot(y_test, label='True Values', color='red')\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Deep Ensemble Predictions with Uncertainty')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6753863",
      "metadata": {
        "id": "b6753863"
      },
      "source": [
        "####  5. pistemic, and aleatoric uncertainty decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8131fd5",
      "metadata": {
        "id": "d8131fd5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# Define the function to create the neural network model\n",
        "def create_model():\n",
        "    inputs = keras.layers.Input(shape=(X_train.shape[1],))\n",
        "    hidden1 = keras.layers.Dense(64, activation='relu')(inputs)\n",
        "    hidden2 = keras.layers.Dense(64, activation='relu')(hidden1)\n",
        "    # Output layer for mean prediction\n",
        "    mean_output = keras.layers.Dense(1)(hidden2)\n",
        "    # Output layer for variance prediction (using softplus activation)\n",
        "    variance_output = keras.layers.Dense(1, activation='softplus')(hidden2)\n",
        "    model = keras.Model(inputs=inputs, outputs=[mean_output, variance_output])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Initialize an empty list to store the ensemble models and predictions\n",
        "ensemble_models = []\n",
        "ensemble_predictions = []\n",
        "\n",
        "# Define the number of ensemble models\n",
        "num_models = 5\n",
        "\n",
        "# Create and train multiple models\n",
        "for _ in range(num_models):\n",
        "    # Create a new instance of the model\n",
        "    model = create_model()\n",
        "\n",
        "    # Train the model on the training data\n",
        "    model.fit(X_train, [y_train, y_train], epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "    # Add the trained model to the ensemble\n",
        "    ensemble_models.append(model)\n",
        "\n",
        "    # Make predictions using the trained model\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Append predictions to the list of ensemble predictions\n",
        "    ensemble_predictions.append(predictions)\n",
        "\n",
        "# Compute ensemble mean and variance predictions\n",
        "ensemble_predictions_array = np.array(ensemble_predictions)\n",
        "mean_predictions = np.mean(ensemble_predictions_array[:, 0, :], axis=0)\n",
        "variance_predictions = np.mean(ensemble_predictions_array[:, 1, :], axis=0)\n",
        "\n",
        "# Compute aleatoric and epistemic uncertainties\n",
        "aleatoric_uncertainty = np.mean(variance_predictions)\n",
        "epistemic_uncertainty = np.mean(np.var(ensemble_predictions_array[:, 0, :], axis=0))\n",
        "\n",
        "# Evaluate the uncertainties\n",
        "print(\"Aleatoric Uncertainty:\", aleatoric_uncertainty)\n",
        "print(\"Epistemic Uncertainty:\", epistemic_uncertainty)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90df2f2d",
      "metadata": {
        "id": "90df2f2d"
      },
      "outputs": [],
      "source": [
        "# Flatten predictions\n",
        "mean_predictions_flat = mean_predictions.flatten()\n",
        "variance_predictions_flat = variance_predictions.flatten()\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot true values\n",
        "plt.scatter(range(len(y_test)), y_test, color='red', label='True Values')\n",
        "\n",
        "# Plot mean predictions\n",
        "plt.plot(mean_predictions_flat, label='Mean Predictions', color='blue')\n",
        "\n",
        "# Plot uncertainty (e.g., standard deviation)\n",
        "plt.fill_between(range(len(y_test)), mean_predictions_flat - np.sqrt(variance_predictions_flat),\n",
        "                 mean_predictions_flat + np.sqrt(variance_predictions_flat), color='gray', alpha=0.3, label='Uncertainty')\n",
        "\n",
        "plt.xlabel('Samples')\n",
        "plt.ylabel('Target Variable')\n",
        "plt.title('Model Predictions with Uncertainty')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a0e1e69",
      "metadata": {
        "id": "8a0e1e69"
      },
      "source": [
        "### 6. variational inferecn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d22a3c2",
      "metadata": {
        "id": "3d22a3c2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the probabilistic model\n",
        "def probabilistic_model(data):\n",
        "    # Prior distribution for the parameter\n",
        "    prior = np.random.normal(loc=0., scale=1.)\n",
        "    # Likelihood of the data given the parameter\n",
        "    likelihood = np.random.normal(loc=data, scale=1.)\n",
        "    # Return the joint distribution\n",
        "    return prior, likelihood\n",
        "\n",
        "# Perform Monte Carlo approximation for variational inference\n",
        "def monte_carlo_inference(data, num_samples=1000):\n",
        "    posterior_samples = []\n",
        "    for _ in range(num_samples):\n",
        "        prior_sample, likelihood_sample = probabilistic_model(data)\n",
        "        posterior_samples.append(prior_sample * likelihood_sample)\n",
        "    return np.array(posterior_samples)\n",
        "\n",
        "# Extract data from normalized_df (assuming it contains your features)\n",
        "data = normalized_df_real.values\n",
        "\n",
        "# Perform Monte Carlo inference\n",
        "posterior_samples = monte_carlo_inference(data)\n",
        "\n",
        "# Compute the posterior mean and standard deviation\n",
        "posterior_mean = np.mean(posterior_samples)\n",
        "posterior_stddev = np.std(posterior_samples)\n",
        "\n",
        "# Compute uncertainty as the standard deviation of the posterior samples\n",
        "uncertainty = np.std(posterior_samples)\n",
        "\n",
        "print(\"Posterior mean:\", posterior_mean)\n",
        "print(\"Posterior standard deviation:\", posterior_stddev)\n",
        "print(\"Uncertainty:\", uncertainty)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ea9cb5",
      "metadata": {
        "id": "b3ea9cb5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Flatten the posterior_samples array\n",
        "flattened_samples = posterior_samples.flatten()\n",
        "\n",
        "# Plot the histogram of flattened posterior samples\n",
        "plt.hist(flattened_samples, bins=30, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "plt.axvline(x=posterior_mean, color='red', linestyle='--', label='Posterior Mean')\n",
        "plt.xlabel('Parameter Value')\n",
        "plt.ylabel('Density')\n",
        "plt.title('Posterior Distribution')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print uncertainty\n",
        "print(\"Uncertainty (Standard Deviation of Posterior):\", uncertainty)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a0d086c",
      "metadata": {
        "id": "7a0d086c"
      },
      "source": [
        "### 7. confromal inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b4e2bd5",
      "metadata": {
        "id": "5b4e2bd5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'target_variable' is the name of the column you want to predict\n",
        "target_variable = 'pt'\n",
        "\n",
        "# Define the quantiles for quantile regression\n",
        "quantiles = [0.1, 0.5, 0.9]\n",
        "\n",
        "data = normalized_df_real\n",
        "# Initialize a list to store the quantile predictions\n",
        "quantile_results = []\n",
        "\n",
        "# Perform quantile regression for each quantile\n",
        "for quantile in quantiles:\n",
        "    # Fit quantile regression model\n",
        "    quantile_model = sm.QuantReg(data[target_variable], data.drop(columns=[target_variable])).fit(q=quantile)\n",
        "\n",
        "    # Predict conditional quantiles\n",
        "    quantile_prediction = quantile_model.predict(data.drop(columns=[target_variable]))\n",
        "\n",
        "    # Append quantile predictions to the results list\n",
        "    quantile_results.append(quantile_prediction)\n",
        "\n",
        "# Convert quantile results to a DataFrame\n",
        "quantile_df = pd.DataFrame(np.array(quantile_results).T, columns=[f'Quantile_{q}' for q in quantiles])\n",
        "\n",
        "# Calculate uncertainty as the difference between upper and lower quantiles\n",
        "quantile_df['Uncertainty'] = quantile_df['Quantile_0.9'] - quantile_df['Quantile_0.1']\n",
        "\n",
        "# Compute the mean uncertainty\n",
        "mean_uncertainty = quantile_df['Uncertainty'].mean()\n",
        "\n",
        "print(\"Mean uncertainty:\", mean_uncertainty)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cea4fd8",
      "metadata": {
        "id": "0cea4fd8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot actual values\n",
        "plt.scatter(data.index, data[target_variable], color='black', label='Actual')\n",
        "\n",
        "# Plot quantile predictions\n",
        "for i, quantile in enumerate(quantiles):\n",
        "    plt.plot(data.index, quantile_df[f'Quantile_{quantile}'], label=f'Quantile {quantile}', linestyle='--')\n",
        "\n",
        "# Plot uncertainty bounds\n",
        "plt.fill_between(data.index, quantile_df['Quantile_0.1'], quantile_df['Quantile_0.9'], color='gray', alpha=0.3, label='Uncertainty')\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel(target_variable)\n",
        "plt.title('Quantile Regression with Uncertainty Bounds')\n",
        "plt.legend()\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4a97ea3",
      "metadata": {
        "id": "e4a97ea3"
      },
      "source": [
        "### 8. bootstrapedd ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379f9857",
      "metadata": {
        "id": "379f9857"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import resample\n",
        "from sklearn.linear_model import LinearRegression  # Example model, replace with your desired model\n",
        "\n",
        "# Define the ensemble size\n",
        "ensemble_size = 5  # You can adjust this as needed\n",
        "\n",
        "# Initialize an empty list to store the ensemble models\n",
        "ensemble_models = []\n",
        "\n",
        "# Define the number of bootstrap samples\n",
        "num_bootstraps = 100  # You can adjust this as needed\n",
        "\n",
        "# Perform bootstrapped ensemble\n",
        "for _ in range(ensemble_size):\n",
        "    # Sample a bootstrap sample with replacement\n",
        "    bootstrap_sample = resample(data, replace=True, n_samples=len(data))\n",
        "\n",
        "    # Train a model on the bootstrap sample (replace `YourModel` with your desired model)\n",
        "    model = LinearRegression()  # Example model, replace with your desired model\n",
        "    model.fit(bootstrap_sample.drop(columns=[target_variable]), bootstrap_sample[target_variable])\n",
        "\n",
        "    # Add the trained model to the ensemble\n",
        "    ensemble_models.append(model)\n",
        "\n",
        "# Make predictions using each model\n",
        "ensemble_predictions = [model.predict(data.drop(columns=[target_variable])) for model in ensemble_models]\n",
        "\n",
        "# Aggregate predictions from all models (for example, you can take the mean or median)\n",
        "final_predictions = np.mean(ensemble_predictions, axis=0)  # Adjust aggregation method as needed\n",
        "\n",
        "# Compute uncertainty as the standard deviation of predictions from all models\n",
        "uncertainty = np.std(ensemble_predictions, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "print(uncertainty)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e402ad42",
      "metadata": {
        "id": "e402ad42"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming `final_predictions` contains your final predictions and `uncertainty` contains the uncertainty\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.errorbar(range(len(final_predictions)), final_predictions, yerr=uncertainty, fmt='o', color='blue', ecolor='red', capsize=5)\n",
        "plt.xlabel('Data Point Index')\n",
        "plt.ylabel('Prediction')\n",
        "plt.title('Bootstrapped Ensemble Predictions with Uncertainty')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "767e612e",
      "metadata": {
        "id": "767e612e"
      },
      "source": [
        "### 9. quantile regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f15d4d97",
      "metadata": {
        "id": "f15d4d97"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Define the quantiles for quantile regression\n",
        "quantiles = [0.1, 0.5, 0.9]  # You can adjust these as needed\n",
        "\n",
        "# Initialize a list to store the quantile predictions\n",
        "quantile_results = []\n",
        "\n",
        "# Perform quantile regression for each quantile\n",
        "for quantile in quantiles:\n",
        "    # Fit quantile regression model\n",
        "    quantile_model = sm.QuantReg(data[target_variable], data.drop(columns=[target_variable])).fit(q=quantile)\n",
        "\n",
        "    # Predict conditional quantiles\n",
        "    quantile_prediction = quantile_model.predict(data.drop(columns=[target_variable]))\n",
        "\n",
        "    # Append quantile predictions to the results list\n",
        "    quantile_results.append(quantile_prediction)\n",
        "\n",
        "# Convert quantile results to a DataFrame\n",
        "quantile_df = pd.DataFrame(np.array(quantile_results).T, columns=[f'Quantile_{q}' for q in quantiles])\n",
        "\n",
        "# Calculate uncertainty as the difference between upper and lower quantiles\n",
        "quantile_df['Uncertainty'] = quantile_df['Quantile_0.9'] - quantile_df['Quantile_0.1']\n",
        "\n",
        "# Compute the mean uncertainty\n",
        "mean_uncertainty = quantile_df['Uncertainty'].mean()\n",
        "\n",
        "print(\"Mean uncertainty:\", mean_uncertainty)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7243431d",
      "metadata": {
        "id": "7243431d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the quantile predictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(data[target_variable], quantile_df['Quantile_0.5'], color='b', label='Median Prediction')\n",
        "plt.plot(data[target_variable], quantile_df['Quantile_0.1'], color='r', linestyle='--', label='10th Quantile')\n",
        "plt.plot(data[target_variable], quantile_df['Quantile_0.9'], color='r', linestyle='--', label='90th Quantile')\n",
        "plt.fill_between(data[target_variable], quantile_df['Quantile_0.1'], quantile_df['Quantile_0.9'], color='r', alpha=0.2)\n",
        "\n",
        "# Add uncertainty visualization with absolute values\n",
        "uncertainty_abs = quantile_df['Uncertainty'].abs()\n",
        "plt.errorbar(data[target_variable], quantile_df['Quantile_0.5'], yerr=uncertainty_abs, fmt='o', color='b', alpha=0.5, label='Uncertainty')\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel('Target Variable')\n",
        "plt.ylabel('Predicted Value')\n",
        "plt.title('Quantile Regression with Uncertainty')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b58a196",
      "metadata": {
        "id": "0b58a196"
      },
      "source": [
        "### 10. kenel density"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff74a8cf",
      "metadata": {
        "id": "ff74a8cf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Assuming `data` contains your dataset and `target_variable` is the column you want to predict\n",
        "# Extract the target variable data\n",
        "target_data = data[target_variable].values.reshape(-1, 1)\n",
        "\n",
        "# Define the range of values over which to estimate the PDF\n",
        "x_values = np.linspace(target_data.min(), target_data.max(), 1000).reshape(-1, 1)\n",
        "\n",
        "# Number of bootstrap samples\n",
        "num_bootstraps = 100  # Adjust as needed\n",
        "\n",
        "# Initialize an empty list to store density estimates from each bootstrap sample\n",
        "density_estimates = []\n",
        "\n",
        "# Fit kernel density estimation model and perform bootstrapping\n",
        "for _ in range(num_bootstraps):\n",
        "    # Sample a bootstrap sample with replacement\n",
        "    bootstrap_sample = resample(target_data, replace=True, n_samples=len(target_data))\n",
        "\n",
        "    # Fit kernel density estimation model on the bootstrap sample\n",
        "    kde = KernelDensity(bandwidth=0.1, kernel='gaussian')  # Adjust bandwidth and kernel as needed\n",
        "    kde.fit(bootstrap_sample)\n",
        "\n",
        "    # Estimate the PDF at the specified points\n",
        "    log_density_values = kde.score_samples(x_values)  # Log-density values\n",
        "\n",
        "    # Convert log-density values to actual density values\n",
        "    density_values = np.exp(log_density_values)\n",
        "\n",
        "    # Append density estimate to the list\n",
        "    density_estimates.append(density_values)\n",
        "\n",
        "# Compute the mean and standard deviation of density estimates across bootstrap samples\n",
        "mean_density = np.mean(density_estimates, axis=0)\n",
        "std_density = np.std(density_estimates, axis=0)\n",
        "\n",
        "# Compute upper and lower bounds of the confidence interval\n",
        "lower_bound = mean_density - 1.96 * std_density  # 95% confidence interval\n",
        "upper_bound = mean_density + 1.96 * std_density  # 95% confidence interval\n",
        "\n",
        "# Plot the estimated probability density function (PDF) with uncertainty\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(x_values, mean_density, color='b', label='Mean PDF')\n",
        "plt.fill_between(x_values.ravel(), lower_bound, upper_bound, color='r', alpha=0.2, label='95% Confidence Interval')\n",
        "\n",
        "# Add labels and legend\n",
        "plt.xlabel('Target Variable')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.title('Kernel Density Estimation with Uncertainty')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbf387fb",
      "metadata": {
        "id": "cbf387fb"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d42e10d1",
      "metadata": {
        "id": "d42e10d1"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
